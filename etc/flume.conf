agent.sources = r1
agent.channels = c1
agent.sinks = k1

# Describe/configure the source

agent.sources.r1.type = org.apache.flume.source.kafka.KafkaSource
agent.sources.r1.batchSize = 300
agent.sources.r1.batchDurationMillis = 100
agent.sources.r1.kafka.bootstrap.servers = kafka:9092
agent.sources.r1.kafka.topics = bigdata-tag
agent.sources.r1.kafka.consumer.group.id = flume-consumer

# Describe the sink
agent.sinks.k1.type = logger

# Use a channel which buffers events in memory
agent.channels.c1.type = file
agent.channels.c1.capacity = 15000
agent.channels.c1.transactionCapacity =300

# Bind the source and sink to the channel
agent.sources.r1.channels = c1
agent.sinks.k1.channel = c1

agent.sinks.k1.type = org.apache.kudu.flume.sink.KuduSink
agent.sinks.k1.producer =  com.example.kudu.flume.sink.JsonKuduOperationsProducer2
agent.sinks.k1.masterAddresses = kudu-master-0.kudu-masters.apache-kudu.svc.cluster.local:7051,kudu-master-1.kudu-masters.apache-kudu.svc.cluster.local:7051,kudu-master-2.kudu-masters.apache-kudu.svc.cluster.local:7051,kudu-master-3.kudu-masters.apache-kudu.svc.cluster.local:7051,kudu-master-4.kudu-masters.apache-kudu.svc.cluster.local:7051
agent.sinks.k1.tableName = impala::default.tag
agent.sinks.k1.batchSize = 100
